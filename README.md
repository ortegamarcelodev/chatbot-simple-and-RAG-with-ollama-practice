# ğŸ¤– RAG Chat con PDFs - PrÃ¡ctica IA

Proyecto de prÃ¡ctica que implementa un sistema de chat con inteligencia artificial e integrado en una API usando **RAG (Retrieval-Augmented Generation)** para consultar documentos PDF y un chat conversacional bÃ¡sico sobre la Segunda Guerra Mundial y todo sobre un servidor creado con FastAPI.

## âœ¨ CaracterÃ­sticas

- ğŸ“„ **Carga y procesa archivos PDF** usando embeddings vectoriales
- ğŸ’¬ **Chat con RAG**: Responde preguntas basadas en el contenido de los PDFs cargados
- ğŸ—¨ï¸ **Chat simple**: ConversaciÃ³n sobre temas de la Segunda Guerra Mundial
- ğŸ” **Vector Store persistente**: Los PDFs procesados se almacenan localmente
- âš¡ **API REST con FastAPI**: Endpoints para subir PDFs y hacer consultas

## ğŸ› ï¸ TecnologÃ­as

- **FastAPI** - Framework web
- **LangChain** - OrquestaciÃ³n de LLMs y RAG
- **Ollama** - LLM local (llama3.2)
- **ChromaDB** - Base de datos vectorial
- **PyPDF** - Procesamiento de PDFs

## ğŸ“‹ Requisitos Previos

- Python 3.8+
- [Ollama](https://ollama.ai/) instalado con el modelo `llama3.2:latest` y `nomic-embed-text:latest`

```bash
# Instalar modelos de Ollama
ollama pull llama3.2:latest
ollama pull nomic-embed-text:latest
```

## ğŸš€ InstalaciÃ³n

### 1. Crear carpeta y clonar el repositorio

```bash
mkdir practica-ia
cd practica-ia
git clone https://github.com/ortegamarcelodev/chatbot-simple-and-RAG-with-ollama-practice.git
```

### 2. Crear entorno virtual

**OpciÃ³n A: Con `uv` (recomendado si lo tienes instalado)**

```bash
uv venv
```

**OpciÃ³n B: Con Python estÃ¡ndar**

```bash
python -m venv .venv
```

### 3. Activar el entorno virtual

**En Windows (PowerShell):**

```bash
.venv\Scripts\Activate.ps1
```

**En Windows (CMD):**

```bash
.venv\Scripts\activate.bat
```

**En Linux/Mac:**

```bash
source .venv/bin/activate
```

### 4. Instalar dependencias

**Con `uv`:**

```bash
uv pip install -r requirements.txt
```

**Con pip estÃ¡ndar:**

```bash
pip install -r requirements.txt
```

## ğŸ® Uso

### Iniciar el servidor

```bash
uvicorn main:app --reload
```

El servidor estarÃ¡ disponible en `http://localhost:8000`

### ğŸ“š DocumentaciÃ³n de la API

Una vez iniciado el servidor, visita:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ”— Endpoints

### 1. Subir PDF

Carga un archivo PDF y lo procesa para el RAG.

```http
POST /upload-pdf
Content-Type: multipart/form-data

file: <archivo.pdf>
```

**Respuesta:**
```json
{
  "status": "success",
  "message": "PDF 'archivo.pdf' procesado exitosamente",
  "chunks": 42
}
```

### 2. Chat con RAG (Consulta PDFs)

Realiza preguntas sobre los PDFs cargados.

```http
POST /answers
Content-Type: application/json

{
  "question": "Â¿CuÃ¡l es el tema principal del documento?"
}
```

**Respuesta:**
```json
{
  "answer": "El documento trata sobre..."
}
```

### 3. Chat Simple

ConversaciÃ³n sobre la Segunda Guerra Mundial sin contexto de PDFs.

```http
POST /chat
Content-Type: application/json

{
  "question": "Â¿CuÃ¡ndo empezÃ³ la Segunda Guerra Mundial?"
}
```

**Respuesta:**
```
La Segunda Guerra Mundial comenzÃ³ el 1 de septiembre de 1939...
```

## ğŸ“ Estructura del Proyecto

```
practica-ia/
â”œâ”€â”€ main.py              # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ routes.py            # DefiniciÃ³n de endpoints
â”œâ”€â”€ chatController.py    # LÃ³gica del RAG chain
â”œâ”€â”€ pdfLoader.py         # Carga y procesamiento de PDFs
â”œâ”€â”€ vectorStore.py       # ConfiguraciÃ³n del vector store
â”œâ”€â”€ retriever.py         # RecuperaciÃ³n de documentos
â”œâ”€â”€ requirements.txt     # Dependencias
â”œâ”€â”€ .gitignore          # Archivos ignorados por git
â””â”€â”€ vector_store/       # Almacenamiento persistente (generado)
```

## ğŸ§ª Ejemplo de Uso

1. **Subir un PDF:**
   ```bash
   curl -X POST "http://localhost:8000/upload-pdf" \
     -F "file=@documento.pdf"
   ```

2. **Hacer una pregunta sobre el PDF:**
   ```bash
   curl -X POST "http://localhost:8000/answers" \
     -H "Content-Type: application/json" \
     -d '{"question": "Â¿De quÃ© trata el documento?"}'
   ```

3. **Chat simple:**
   ```bash
   curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"question": "Â¿QuÃ© fue el DÃ­a D?"}'
   ```

## ğŸ“ Notas

- Los PDFs procesados se almacenan en la carpeta `vector_store/` para consultas futuras
- El chat simple estÃ¡ limitado a preguntas sobre la Segunda Guerra Mundial
- AsegÃºrate de tener Ollama corriendo en segundo plano

## ğŸ¤ Contribuciones

Este es un proyecto de prÃ¡ctica educativo. SiÃ©ntete libre de hacer fork y experimentar!

## ğŸ“„ Licencia

MIT

---
